{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f61469b",
   "metadata": {},
   "source": [
    "# Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9610fb12",
   "metadata": {},
   "source": [
    " - The objective of this project is to analyze the datasets results of the bank to identify which customer  will make \n",
    "   transactions in future ,irrespective of the amount of money transacted .\n",
    "  \n",
    " -  Dataset had an imbalance data with the majority of negative result distribution. As the bank's data scientists, we decided       to focus on minimizing both False Negative Class and False positive class.\n",
    "\n",
    " -  Evaluation metric that we will use is F1 Score.\n",
    " 1) In False positive class where we predicted clients that will not made  a transaction, turns out they actually made a            transaction .\n",
    " 2) In False negative class where we predicted clients that will  made a transaction, turns out they actually not made a            transaction ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65418f",
   "metadata": {},
   "source": [
    "## Business Case:- Create a predictive model which will help the bank to identify which customer will make transactions in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ac79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba31e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('train(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c43611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>train_199995</td>\n",
       "      <td>0</td>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>train_199996</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>train_199997</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>train_199998</td>\n",
       "      <td>0</td>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>train_199999</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
       "0            train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607   \n",
       "1            train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622   \n",
       "2            train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825   \n",
       "3            train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846   \n",
       "4            train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772   \n",
       "...              ...     ...      ...     ...      ...     ...      ...   \n",
       "199995  train_199995       0  11.4880 -0.4956   8.2622  3.5142  10.3404   \n",
       "199996  train_199996       0   4.9149 -2.4484  16.7052  6.6345   8.3096   \n",
       "199997  train_199997       0  11.2232 -5.0518  10.5127  5.6456   9.3410   \n",
       "199998  train_199998       0   9.7148 -8.6098  13.6104  5.7930  12.5173   \n",
       "199999  train_199999       0  10.8762 -5.7105  12.1183  8.0328  11.5577   \n",
       "\n",
       "          var_5   var_6    var_7  ...  var_190  var_191  var_192  var_193  \\\n",
       "0       -9.2834  5.1187  18.6266  ...   4.4354   3.9642   3.1364   1.6910   \n",
       "1        7.0433  5.6208  16.5338  ...   7.6421   7.7214   2.5837  10.9516   \n",
       "2       -9.0837  6.9427  14.6155  ...   2.9057   9.7905   1.6704   1.6858   \n",
       "3       -1.8361  5.8428  14.9250  ...   4.4666   4.7433   0.7178   1.4214   \n",
       "4        2.4486  5.9405  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942   \n",
       "...         ...     ...      ...  ...      ...      ...      ...      ...   \n",
       "199995  11.6081  5.6709  15.1516  ...   6.1415  13.2305   3.9901   0.9388   \n",
       "199996 -10.5628  5.8802  21.5940  ...   4.9611   4.6549   0.6998   1.8341   \n",
       "199997  -5.4086  4.5555  21.5571  ...   4.0651   5.4414   3.1032   4.8793   \n",
       "199998   0.5339  6.0479  17.0152  ...   2.6840   8.6587   2.7337  11.1178   \n",
       "199999   0.3488  5.2839  15.2058  ...   8.9842   1.6893   0.1276   0.3766   \n",
       "\n",
       "        var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "0       18.5227  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "1       15.4305   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "2       21.6042   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "3       23.0347  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4       13.2876  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "...         ...      ...      ...      ...      ...      ...  \n",
       "199995  18.0249  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "199996  22.2717   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "199997  23.5311  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "199998  20.4158  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "199999  15.2101  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[200000 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3670cd01",
   "metadata": {},
   "source": [
    "## Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc7dc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd2422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>train_199995</td>\n",
       "      <td>0</td>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>train_199996</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>train_199997</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>train_199998</td>\n",
       "      <td>0</td>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>train_199999</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
       "199995  train_199995       0  11.4880 -0.4956   8.2622  3.5142  10.3404   \n",
       "199996  train_199996       0   4.9149 -2.4484  16.7052  6.6345   8.3096   \n",
       "199997  train_199997       0  11.2232 -5.0518  10.5127  5.6456   9.3410   \n",
       "199998  train_199998       0   9.7148 -8.6098  13.6104  5.7930  12.5173   \n",
       "199999  train_199999       0  10.8762 -5.7105  12.1183  8.0328  11.5577   \n",
       "\n",
       "          var_5   var_6    var_7  ...  var_190  var_191  var_192  var_193  \\\n",
       "199995  11.6081  5.6709  15.1516  ...   6.1415  13.2305   3.9901   0.9388   \n",
       "199996 -10.5628  5.8802  21.5940  ...   4.9611   4.6549   0.6998   1.8341   \n",
       "199997  -5.4086  4.5555  21.5571  ...   4.0651   5.4414   3.1032   4.8793   \n",
       "199998   0.5339  6.0479  17.0152  ...   2.6840   8.6587   2.7337  11.1178   \n",
       "199999   0.3488  5.2839  15.2058  ...   8.9842   1.6893   0.1276   0.3766   \n",
       "\n",
       "        var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "199995  18.0249  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "199996  22.2717   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "199997  23.5311  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "199998  20.4158  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "199999  15.2101  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bfa2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d8efb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f130adb",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac561c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_code    0\n",
       "target     0\n",
       "var_0      0\n",
       "var_1      0\n",
       "var_2      0\n",
       "          ..\n",
       "var_195    0\n",
       "var_196    0\n",
       "var_197    0\n",
       "var_198    0\n",
       "var_199    0\n",
       "Length: 202, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d84f9e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6728cd",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b144e",
   "metadata": {},
   "source": [
    "# Checking correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3467d45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feature1, feature2, corr]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "corrmat = X.corr()\n",
    "corrmat = corrmat.abs().unstack() # absolute value of corr coef\n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.9]\n",
    "corrmat = corrmat[corrmat < 1]\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356d232",
   "metadata": {},
   "source": [
    "# Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "389f59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating X and \n",
    "X=data.drop(labels=['ID_code','target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf09846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>-0.6209</td>\n",
       "      <td>5.6669</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>-3.6797</td>\n",
       "      <td>6.0019</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>6.1629</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>-2.1926</td>\n",
       "      <td>8.7542</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>-0.4541</td>\n",
       "      <td>9.3688</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
       "0        8.9255 -6.7863  11.9081  5.0930  11.4607  -9.2834  5.1187  18.6266   \n",
       "1       11.5006 -4.1473  13.8588  5.3890  12.3622   7.0433  5.6208  16.5338   \n",
       "2        8.6093 -2.7457  12.0805  7.8928  10.5825  -9.0837  6.9427  14.6155   \n",
       "3       11.0604 -2.1518   8.9522  7.1957  12.5846  -1.8361  5.8428  14.9250   \n",
       "4        9.8369 -1.4834  12.8746  6.6375  12.2772   2.4486  5.9405  19.2514   \n",
       "...         ...     ...      ...     ...      ...      ...     ...      ...   \n",
       "199995  11.4880 -0.4956   8.2622  3.5142  10.3404  11.6081  5.6709  15.1516   \n",
       "199996   4.9149 -2.4484  16.7052  6.6345   8.3096 -10.5628  5.8802  21.5940   \n",
       "199997  11.2232 -5.0518  10.5127  5.6456   9.3410  -5.4086  4.5555  21.5571   \n",
       "199998   9.7148 -8.6098  13.6104  5.7930  12.5173   0.5339  6.0479  17.0152   \n",
       "199999  10.8762 -5.7105  12.1183  8.0328  11.5577   0.3488  5.2839  15.2058   \n",
       "\n",
       "         var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "0      -4.9200  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227   \n",
       "1       3.1468  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   \n",
       "2      -4.9193  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   \n",
       "3      -5.8609  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347   \n",
       "4       6.2654  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
       "...        ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "199995 -0.6209  5.6669  ...   6.1415  13.2305   3.9901   0.9388  18.0249   \n",
       "199996 -3.6797  6.0019  ...   4.9611   4.6549   0.6998   1.8341  22.2717   \n",
       "199997  0.1202  6.1629  ...   4.0651   5.4414   3.1032   4.8793  23.5311   \n",
       "199998 -2.1926  8.7542  ...   2.6840   8.6587   2.7337  11.1178  20.4158   \n",
       "199999 -0.4541  9.3688  ...   8.9842   1.6893   0.1276   0.3766  15.2101   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "0       -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "1        2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "2        3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "3       -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4       -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "199995  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "199996   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "199997  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "199998  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "199999  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[200000 rows x 200 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16c4e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42785307, 0.32482435, 0.56805853, ..., 0.43095798, 0.32765751,\n",
       "        0.56064496],\n",
       "       [0.55721218, 0.42863943, 0.6812351 , ..., 0.4682771 , 0.6095461 ,\n",
       "        0.60582746],\n",
       "       [0.41196889, 0.48377668, 0.57806091, ..., 0.38194973, 0.42583343,\n",
       "        0.58273586],\n",
       "       ...,\n",
       "       [0.5432771 , 0.39305749, 0.4870996 , ..., 0.45612437, 0.38087342,\n",
       "        0.63919915],\n",
       "       [0.46750324, 0.25309006, 0.66682332, ..., 0.67445942, 0.46661746,\n",
       "        0.37047369],\n",
       "       [0.5258457 , 0.36714503, 0.580254  , ..., 0.36840624, 0.29469964,\n",
       "        0.57890533]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## scaling data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale=MinMaxScaler()\n",
    "scale.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c91ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating new dataframe\n",
    "df=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff97ff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>-0.6209</td>\n",
       "      <td>5.6669</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>-3.6797</td>\n",
       "      <td>6.0019</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>6.1629</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>-2.1926</td>\n",
       "      <td>8.7542</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>-0.4541</td>\n",
       "      <td>9.3688</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
       "0        8.9255 -6.7863  11.9081  5.0930  11.4607  -9.2834  5.1187  18.6266   \n",
       "1       11.5006 -4.1473  13.8588  5.3890  12.3622   7.0433  5.6208  16.5338   \n",
       "2        8.6093 -2.7457  12.0805  7.8928  10.5825  -9.0837  6.9427  14.6155   \n",
       "3       11.0604 -2.1518   8.9522  7.1957  12.5846  -1.8361  5.8428  14.9250   \n",
       "4        9.8369 -1.4834  12.8746  6.6375  12.2772   2.4486  5.9405  19.2514   \n",
       "...         ...     ...      ...     ...      ...      ...     ...      ...   \n",
       "199995  11.4880 -0.4956   8.2622  3.5142  10.3404  11.6081  5.6709  15.1516   \n",
       "199996   4.9149 -2.4484  16.7052  6.6345   8.3096 -10.5628  5.8802  21.5940   \n",
       "199997  11.2232 -5.0518  10.5127  5.6456   9.3410  -5.4086  4.5555  21.5571   \n",
       "199998   9.7148 -8.6098  13.6104  5.7930  12.5173   0.5339  6.0479  17.0152   \n",
       "199999  10.8762 -5.7105  12.1183  8.0328  11.5577   0.3488  5.2839  15.2058   \n",
       "\n",
       "         var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "0      -4.9200  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227   \n",
       "1       3.1468  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   \n",
       "2      -4.9193  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   \n",
       "3      -5.8609  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347   \n",
       "4       6.2654  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
       "...        ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "199995 -0.6209  5.6669  ...   6.1415  13.2305   3.9901   0.9388  18.0249   \n",
       "199996 -3.6797  6.0019  ...   4.9611   4.6549   0.6998   1.8341  22.2717   \n",
       "199997  0.1202  6.1629  ...   4.0651   5.4414   3.1032   4.8793  23.5311   \n",
       "199998 -2.1926  8.7542  ...   2.6840   8.6587   2.7337  11.1178  20.4158   \n",
       "199999 -0.4541  9.3688  ...   8.9842   1.6893   0.1276   0.3766  15.2101   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "0       -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "1        2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "2        3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "3       -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4       -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "199995  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "199996   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "199997  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "199998  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "199999  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[200000 rows x 200 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74dd0c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfb0lEQVR4nO3deVhU1R8G8HcY9lUBZREE3FGUNXdzSXHJPQOXUsssyzW1UitNzdzKfa3UNvfck0w0xT2NRUVRXEBQQQSVVRiYOb8/yPk1gQoI3Jnh/TzPPE9z59473zuXaV7vOfccmRBCgIiIiEhPGEhdABEREVF5YrghIiIivcJwQ0RERHqF4YaIiIj0CsMNERER6RWGGyIiItIrDDdERESkVxhuiIiISK8w3BAREZFeYbgh0lI//PADZDLZUx9Hjx6t8PeOj4+v1G3Lg0wmwxdffPHU15cuXQqZTIYDBw48dZ3vvvsOMpkMO3fuLJea3N3dMXz48HLZFxE9n6HUBRDRs23YsAGNGjUqsrxx48YSVPN8r776Kk6fPg0nJyepSynWG2+8gU8++QTr169Ht27dil1nw4YNqFGjBnr16lUu77lr1y5YW1uXy76I6PkYboi0nJeXFwICAqQuo8Rq1KiBGjVqSF3GU9nZ2aFPnz7YvXs30tLSYGdnp/H6lStXcPr0aUyaNAlGRkYv9F6PHz+GmZkZfH19X2g/RFQ6bJYi0nFbtmyBTCbDihUrNJbPmDEDcrkcoaGhAID4+HjIZDIsWLAAc+bMQe3atWFqaoqAgAAcPnz4ue8TGhqKPn36wMXFBaampqhXrx7ee+89pKamaqxXXLNUhw4d4OXlhXPnzqFdu3YwNzdHnTp1MG/ePKhUKo3tMzIyMHnyZHh4eMDY2Bi1atXChAkTkJ2dXWS9kSNHws7ODpaWlujWrRtiY2NL9JmNGDECCoUCmzZtKvLahg0bAABvv/02AGDmzJlo0aIFbG1tYW1tDT8/P6xbtw7/nXPY3d0dPXv2xM6dO+Hr6wtTU1PMnDlT/dq/m6Vyc3MxadIk+Pj4wMbGBra2tmjVqhX27NlTpB6ZTIYxY8bg559/hqenJ8zNzeHt7Y3ffvutyLpXrlzBoEGD4ODgABMTE9SuXRtDhw5FXl6eep3k5GS89957cHFxgbGxMTw8PDBz5kwUFBSU6LMj0gW8ckOk5ZRKZZEfHplMBrlcDgAYOHAgwsLCMGnSJLRs2RIBAQH4888/8eWXX2LatGno0qWLxrYrVqyAm5sblixZApVKhQULFqB79+4ICwtDq1atnlrHjRs30KpVK7zzzjuwsbFBfHw8Fi1ahLZt2+LixYvPvcqRnJyMIUOGYNKkSZgxYwZ27dqFqVOnwtnZGUOHDgUA5OTkoH379rh9+zamTZuGZs2a4dKlS5g+fTouXryIQ4cOQSaTQQiBvn374tSpU5g+fTpeeuklnDx5Et27dy/RZ9q5c2e4ublh/fr1GDt2rMZn/fPPP6Nly5bqZr/4+Hi89957qF27NgDgzJkzGDt2LO7cuYPp06dr7DciIgIxMTH47LPP4OHhAQsLi2LfPy8vDw8ePMDkyZNRq1YtKBQKHDp0CP3798eGDRvUn8cT+/fvx7lz5zBr1ixYWlpiwYIF6NevH65evYo6deoAAM6fP4+2bdvC3t4es2bNQv369ZGUlIS9e/dCoVDAxMQEycnJaN68OQwMDDB9+nTUrVsXp0+fxpdffon4+Hh1sCPSeYKItNKGDRsEgGIfcrlcY93c3Fzh6+srPDw8xOXLl4WDg4No3769KCgoUK8TFxcnAAhnZ2fx+PFj9fKMjAxha2srOnfuXOS94+Liiq1NpVKJ/Px8cevWLQFA7Nmz55nbtm/fXgAQf/31l8Z+GjduLLp27ap+PnfuXGFgYCDOnTunsd6vv/4qAIiQkBAhhBC///67ACCWLl2qsd6cOXMEADFjxoxi6/63GTNmCAAiIiJCvWzfvn0CgPjuu++K3UapVIr8/Hwxa9YsYWdnJ1Qqlfo1Nzc3IZfLxdWrV4ts5+bmJoYNG/bUWgoKCkR+fr4YMWKE8PX11XgNgHBwcBAZGRnqZcnJycLAwEDMnTtXvaxTp06iWrVqIiUl5anv89577wlLS0tx69YtjeVff/21ACAuXbr01G2JdAmbpYi03E8//YRz585pPP766y+NdUxMTLBt2zakpaXBz88PQghs3rxZfXXn3/r37w9TU1P1cysrK/Tq1QvHjh2DUql8ah0pKSkYNWoUXF1dYWhoCCMjI7i5uQEAYmJinnscjo6OaN68ucayZs2a4datW+rnv/32G7y8vODj44OCggL1o2vXrhp3iB05cgQAMGTIEI39DR48+Ll1PPHWW2/BwMAA69evVy/bsGEDLCwsEBwcrF72559/onPnzrCxsYFcLoeRkRGmT5+OtLQ0pKSkFDmeBg0alOj9t2/fjjZt2sDS0lL9ea5bt67Yz7Jjx46wsrJSP3dwcEDNmjXVn11OTg7CwsIQFBT0zP5Ov/32Gzp27AhnZ2eNz/fJFa+wsLAS1U6k7dgsRaTlPD09S9ShuF69emjXrh3279+P999//6l3Kzk6Oha7TKFQICsrCzY2NkVeV6lUCAwMxN27d/H555+jadOmsLCwgEqlQsuWLfH48ePn1vffjrtAYSj797b37t3D9evXn9rE9aR/T1paGgwNDYvss7hjexo3Nze88sor2LRpE77++mtkZmbit99+w+DBg9VB4uzZswgMDESHDh3w3Xffqfup7N69G3PmzCly3CW9Q2znzp0ICgrC66+/jo8++giOjo4wNDTE6tWrNcLWE8/77B4+fAilUgkXF5dnvu+9e/ewb9++536+RLqO4YZIT3z//ffYv38/mjdvjhUrViA4OBgtWrQosl5ycnKxy4yNjWFpaVnsvqOjo3H+/Hn88MMPGDZsmHr59evXy+8AANjb28PMzKzYH/gnrwOFP/YFBQVF7nYq7tieZcSIEQgNDcWePXtw9+5dKBQKjBgxQv36li1bYGRkhN9++03jatfu3buL3Z9MJivR+/7yyy/w8PDA1q1bNbb5d8ff0rC1tYVcLsft27efuZ69vT2aNWuGOXPmFPu6s7Nzmd6fSNuwWYpID1y8eBHjxo3D0KFDcfz4cTRr1gzBwcF4+PBhkXV37tyJ3Nxc9fPMzEzs27cP7dq1K7YZC/j/j7aJiYnG8rVr15bjUQA9e/bEjRs3YGdnh4CAgCIPd3d3AIXNNACwceNGje2Lu/vpWfr27Qs7OzusX78eGzZsQIMGDdC2bVv16zKZDIaGhhqfy+PHj/Hzzz+X8Qj/v19jY2ONYJOcnFzs3VIlYWZmhvbt22P79u3PvPrSs2dPREdHo27dusV+vgw3pC945YZIy0VHRxd7m27dunVRo0YNZGdnIygoCB4eHli1ahWMjY2xbds2+Pn54a233ipylUEul6NLly6YOHEiVCoV5s+fj4yMDPVty8Vp1KgR6tatiylTpkAIAVtbW+zbt099m3l5mTBhAnbs2IGXX34ZH374IZo1awaVSoWEhAQcPHgQkyZNQosWLRAYGIiXX34ZH3/8MbKzsxEQEICTJ0+WOnSYmJhgyJAhWL58OYQQmDdvnsbrr776KhYtWoTBgwfj3XffRVpaGr7++usiIa+0ntwy/sEHH2DAgAFITEzE7Nmz4eTkhGvXrpVpn0/uXGvRogWmTJmCevXq4d69e9i7dy/Wrl0LKysrzJo1C6GhoWjdujXGjRuHhg0bIjc3F/Hx8QgJCcGaNWue27RFpAsYboi03FtvvVXs8u+++w7vvPMORo0ahYSEBJw7d05963GdOnXw/fff4/XXX8eSJUswYcIE9XZjxoxBbm4uxo0bh5SUFDRp0gT79+9HmzZtnlqDkZER9u3bh/Hjx+O9996DoaEhOnfujEOHDqlvkS4PFhYWOH78OObNm4dvv/0WcXFxMDMzQ+3atdG5c2f1lRsDAwPs3bsXEydOxIIFC6BQKNCmTRuEhIQUO5rzs4wYMQLLli2DXC4vcgt2p06dsH79esyfPx+9evVCrVq1MHLkSNSsWVOj+aq03nrrLaSkpGDNmjVYv3496tSpgylTpuD27dvPDJnP4u3tjbNnz2LGjBmYOnUqMjMz4ejoiE6dOsHY2BhAYZ+gv//+G7Nnz8bChQtx+/ZtWFlZwcPDA926dUP16tXLfExE2kQmxH9GoiIivRQfHw8PDw8sXLgQkydPlrocIqIKwz43REREpFcYboiIiEivsFmKiIiI9Aqv3BAREZFeYbghIiIivcJwQ0RERHqlyo1zo1KpcPfuXVhZWZV4qHQiIiKSlhACmZmZcHZ2hoHBs6/NVLlwc/fuXbi6ukpdBhEREZVBYmLic0fSrnLh5slsv4mJibC2tpa4GiIiIiqJjIwMuLq6qn/Hn6XKhZsnTVHW1tYMN0RERDqmJF1K2KGYiIiI9ArDDREREekVhhsiIiLSKww3REREpFcYboiIiEivMNwQERGRXmG4ISIiIr3CcENERER6heGGiIiI9ArDDREREekVScPNsWPH0KtXLzg7O0Mmk2H37t3P3SYsLAz+/v4wNTVFnTp1sGbNmoovlIiIiHSGpOEmOzsb3t7eWLFiRYnWj4uLQ48ePdCuXTtERkZi2rRpGDduHHbs2FHBlRIREZGukHTizO7du6N79+4lXn/NmjWoXbs2lixZAgDw9PTE33//ja+//hqvvfZaBVVJREREJXXzfhZUAqhX01KyGnSqz83p06cRGBiosaxr1674+++/kZ+fX+w2eXl5yMjI0HgQERFR+RJCYNNfCXh12QmM3RyJvAKlZLXoVLhJTk6Gg4ODxjIHBwcUFBQgNTW12G3mzp0LGxsb9cPV1bUySiUiIqoy0rLyMPKncEzbdRGP85WwtTBCdh7DTYnJZDKN50KIYpc/MXXqVKSnp6sfiYmJFV4jERFRVXHkSgq6LjmOQzH3YCw3wGeveuLnt1vA1sJYspok7XNTWo6OjkhOTtZYlpKSAkNDQ9jZ2RW7jYmJCUxMTCqjPCIioirjsUKJub/H4KfTtwAADRwssSTYF42drSWuTMfCTatWrbBv3z6NZQcPHkRAQACMjIwkqoqIiKhqib6Tjglbo3A9JQsA8FYbd3zSrRFMjeQSV1ZI0nCTlZWF69evq5/HxcUhKioKtra2qF27NqZOnYo7d+7gp59+AgCMGjUKK1aswMSJEzFy5EicPn0a69atw+bNm6U6BCIioipDqRL49thNLAq9inylQE0rE3z9ujdeblBD6tI0SBpu/v77b3Ts2FH9fOLEiQCAYcOG4YcffkBSUhISEhLUr3t4eCAkJAQffvghVq5cCWdnZyxbtoy3gRMREVWwO48eY+LWKPwV9wAA0LWJA+b2byZp35qnkYknPXKriIyMDNjY2CA9PR3W1tK3CxIREWm7PVF38NnuaGTmFsDcWI4vejXB6wEuT72ZpyKU5vdbp/rcEBERUeVJf5yPGXuisTvqLgDAt3Y1LAn2gZudhcSVPRvDDRERERXx1800TNx2HncePYbcQIaxnephTMd6MJRr/ygyDDdERESkpihQYfGhWKwJuwEhgNq25lgc7AN/t+pSl1ZiDDdEREQEALiekoUJWyMRfadwqqKgABdM79UElia6FRd0q1oiIiIqd0II/PJXAubsv4zcfBWqmRthXv+m6OblJHVpZcJwQ0REVIXdz8zDJzsu4M8rKQCAtvXs8fXr3nC0MZW4srJjuCEiIqqiDsfcw8e/XkBatgLGhgb4pFsjvNXaHQYGlXeLd0VguCEiIqpiHiuU+HL/ZWz8q3Cg3EaOVlgy0AeNHPVj/DeGGyIioirk4u10jN8aiZv3swEAI9p64KOuDbVmXqjywHBDRERUBShVAmvCbmBxaCwKVAIO1ib45nUftK1vL3Vp5Y7hhoiISM8lPsjBpG3ncTa+cF6o7l6O+KpfU1TXwnmhygPDDRERkZ4SQmB31B1M330JmXkFsDCW44veTTDAv3LnhapsDDdERER6KP1xPj7bHY195wvnhfKrXQ1Lgn1R285c4soqHsMNERGRnvnrZho+3BqFu+m5kBvIMP6V+vigQ12dmBeqPDDcEBER6Yl8pQpLDsVi1dHCeaHc7MyxJNgHvrV1Z16o8sBwQ0REpAfiU7MxfmsUzic+AgC87u+CGb11b16o8lD1jpiIiEiPCCHwa/htfLH3ErIVSlibGmJu/2Z4tZluzgtVHhhuiIiIdFR6Tj6m7b6I/ReSAADNPWyxONgHtaqZSVyZtBhuiIiIdNC/Ow0bGsjwYZcGGNW+LuQ6Pi9UeWC4ISIi0iH/7TTsbmeOJQN94eNaTerStAbDDRERkY6IT83G+C2ROH87HQAQFOCCGb2awKIKdhp+Fn4aREREWk4Ige3/dBrOYafh52K4ISIi0mLpOfmYtusi9l8s7DTc4p9Ow85VvNPwszDcEBERaakzN9MwkZ2GS43hhoiISMsU12l46UBfeLPTcIkw3BAREWkRdhp+cfykiIiItEBxnYbnvdYMPZqy03BpMdwQERFJ7L+dhlvWscWiIHYaLiuGGyIiIgmd+Wek4aR/Og1PDGyA915mp+EXwXBDREQkgXylCotDY7E6rLDTsIe9BZYE+7DTcDlguCEiIqpkcf90Gr7ATsMVgp8iERFRJRFCYPvft/HFvsJOwzZmRpjbvyk7DZczhhsiIqJKkJ6Tj6m7LiDkYjIAdhquSAw3REREFez0jTRM3Pb/TsOTAhvi3ZfrsNNwBWG4ISIiqiD5ShUWhcZizb86DS8d6INmLtWkLk2vMdwQERFVgP92Gg4OcMX0Xo3ZabgS8BMmIiIqR8V1Gp7Xvym6s9NwpWG4ISIiKiePchSYuvMifo8u7DTcqo4dFgV7w8mGnYYrE8MNERFROWCnYe3BcENERPQC8pUqLDkUi1VHCzsN17G3wNKBvmjqYiN1aVUWww0REVEZJaTlYNyWSEQlPgJQ2Gl4Ru/GMDfmz6uU+OkTERGVwe7IO/hsdzSy8gpgbWqIuf2b4dVm7DSsDRhuiIiISiEzNx8z9lzCzsg7AICX3KtjyUBf1OJIw1qD4YaIiKiEohIfYdzmSCQ8yIGBDBj/SgOM7lgXhnIDqUujf2G4ISIieg6lSmBN2A0sDo1FgUqgVjUzLB3ogwB3W6lLo2Iw3BARET1DcnouPtwahdM30wAAPZs5YU6/prAxM5K4MnoahhsiIqKnOHgpGR/vuIBHOfkwN5ZjZu8mGODvApmMY9doM4YbIiKi/8jNV+LL/Zfxy5kEAIBXLWssG+iLOjUsJa6MSoLhhoiI6F+uJGdg7KZIXEvJAgC8+3IdTA5sCGNDdhrWFQw3REREKJzw8qfTtzAnJAaKAhXsLU2wKMgbLzeoIXVpVEoMN0REVOWlZeXh418v4PCVFABAp0Y1sWBAM9hbmkhcGZUFww0REVVpJ66lYuK2KKRk5sHY0ADTujfCsNbu7DSswxhuiIioSlIUqPDNwatYe+wmAKBeTUssH+QLTydriSujF8VwQ0REVU5cajbGb4nEhdvpAIAhLWrjs1cbw8xYLnFlVB4YboiIqMoQQmBHxB1M3xONHIUS1cyNMK9/M3TzcpS6NCpHDDdERFQlZOTm49Nd0dh3/i4AoGUdWywO9oGTDSe81DeS37S/atUqeHh4wNTUFP7+/jh+/Pgz19+4cSO8vb1hbm4OJycnvPXWW0hLS6ukaomISBeF33qIHkuPY9/5u5AbyPBR14bY+E5LBhs9JWm42bp1KyZMmIBPP/0UkZGRaNeuHbp3746EhIRi1z9x4gSGDh2KESNG4NKlS9i+fTvOnTuHd955p5IrJyIiXaBUCSw7fA1Ba0/j9sPHcLU1w/ZRrTC6Yz3IDXg3lL6SCSGEVG/eokUL+Pn5YfXq1eplnp6e6Nu3L+bOnVtk/a+//hqrV6/GjRs31MuWL1+OBQsWIDExsUTvmZGRARsbG6Snp8Pamj3iiYj01Z1Hj/HhliicjX8AAOjj44zZfb1gbcoJL3VRaX6/Jbtyo1AoEB4ejsDAQI3lgYGBOHXqVLHbtG7dGrdv30ZISAiEELh37x5+/fVXvPrqq5VRMhER6YjfLyah+5JjOBv/ABbGciwK8sbSgb4MNlWEZB2KU1NToVQq4eDgoLHcwcEBycnJxW7TunVrbNy4EcHBwcjNzUVBQQF69+6N5cuXP/V98vLykJeXp36ekZFRPgdARERaJ0dRgNm/Xcbms4VX871dq2HZQB+42VlIXBlVJsk7FP93BEghxFNHhbx8+TLGjRuH6dOnIzw8HAcOHEBcXBxGjRr11P3PnTsXNjY26oerq2u51k9ERNrh0t109Fp+ApvPJkImA97vUBe/jmrFYFMFSdbnRqFQwNzcHNu3b0e/fv3Uy8ePH4+oqCiEhYUV2ebNN99Ebm4utm/frl524sQJtGvXDnfv3oWTk1ORbYq7cuPq6so+N0REekKlElh/Mg4LDlyFQqmCg7UJFgf5oHU9e6lLo3JUmj43kjVLGRsbw9/fH6GhoRrhJjQ0FH369Cl2m5ycHBgaapYslxeOJvm0jGZiYgITE058RkSkj+5n5mHy9vMIi70PAOjs6YAFA5rB1sJY4spISpIO4jdx4kS8+eabCAgIQKtWrfDtt98iISFB3cw0depU3LlzBz/99BMAoFevXhg5ciRWr16Nrl27IikpCRMmTEDz5s3h7Ows5aEQEVElC4u9j0nbziM1Kw8mhgb4rGdjvNGiNie8JGnDTXBwMNLS0jBr1iwkJSXBy8sLISEhcHNzAwAkJSVpjHkzfPhwZGZmYsWKFZg0aRKqVauGTp06Yf78+VIdAhERVbK8AiUWHriK70/EAQAaOlhh2SBfNHS0krgy0haSjnMjBY5zQ0Sku27cz8K4zZG4dLfwztehrdwwrYcnTI044aW+04k+N0RERCUlhMDWc4mYue8yHucrUd3cCAsHeKNzY4fnb0xVDsMNERFptfTH+Zi28yL2X0wCALSpZ4dFQT5wsDaVuDLSVgw3RESktcJvPcC4zVG48+gxDA1kmNy1Id5tVwcGnBeKnoHhhoiItI5SJbD66HUsPnQNSpVAbVtzLBvkCx/XalKXRjqA4YaIiLRKcnouPtwahdM30wAUTnj5ZV8vWHFeKCohhhsiItIah2PuYfL283iYkw9zYzlm9fHCa361OHYNlQrDDRERSS43X4l5v1/BD6fiAQBNnK2xfJAv6tSwlLYw0kkMN0REJKnrKYVj11xOKhy7ZkRbD3zcrSFMDDl2DZUNww0REUlCCIHtf9/GjL2X8DhfCVsLY3zzujc6NqopdWmk4xhuiIio0mXk5uPTXdHYd/4ugMKxaxYH+aAmx66hcsBwQ0RElSoy4SHGbYlE4oPHkBvIMCmwAUa9XJdj11C5YbghIqJKoVIJrDl2A4sOxqJAJeBS3QzLBvnCr3Z1qUsjPcNwQ0REFS4lIxcfbovCyeuFY9f0bOaEr/o3hTXHrqEKwHBDREQV6siVFEzafh4PshUwM5JjZu8meD3AhWPXUIVhuCEiogqRV6DEggNXse5EHADA06lw7Jp6NTl2DVUshhsiIip3N+9nYdyWSETfKRy7Znhrd0zp3gimRhy7hioeww0REZUbIQR2RNzB9D3RyFEoUd3cCAsHeKNzYwepS6MqhOGGiIjKRWZuPj7fHY3dUYVj17SsY4slwb5wtOHYNVS5GG6IiOiFnU98hLGbI5HwIAdyAxk+7Fwf73eoBznHriEJMNwQEVGZqVQC3x2/iYV/XEWBSqBWNTMsG+QDfzdbqUujKozhhoiIyiQlMxeTtp3H8WupAIBXmxaOXWNjxrFrSFoMN0REVGphsfcxaVsUUrMUMDUywIxeTTDwJVeOXUNageGGiIhKTFGgwtcHr+LbYzcBAI0crbB8kC/qO1hJXBnR/zHcEBFRicSnZmPclkhcuJ0OABjayg3Tenhy7BrSOgw3RET0XLsib+OzXdHIVihRzdwIC15rhsAmjlKXRVQshhsiInqqrLwCTN8TjZ0RdwAAzT1ssXSgD5xszCSujOjpGG6IiKhYF2+nY+zmCMSn5cBABkzo3ACjO3LsGtJ+DDdERKRBpRJYfzIO8w9cQb5SwNnGFEsH+eIld45dQ7qB4YaIiNRSs/Iwadt5hMXeBwB0a+KIea81RTVzY4krIyo5hhsiIgIAnLiWig+3ReF+Zh5MDA0wvVdjDG5em2PXkM5huCEiquIKlCosPhSLVUdvQAiggYMllg/yQ0NHjl1DuonhhoioCrvz6DHGbY5E+K2HAIBBzWtjes/GMDPm2DWkuxhuiIiqqAPRyfj41/PIyC2AlYkh5r3WDK82c5K6LKIXxnBDRFTF5OYrMWd/DH4+cwsA4O1aDSsG+cLV1lziyojKB8MNEVEVcj0lC2M2ReBKciYA4L32dTA5sCGM5AYSV0ZUfhhuiIiqACEEfg2/jel7LuFxvhJ2Fsb4JsgbHRrWlLo0onLHcENEpOey8grw+e5o7IosnEKhdV07LAn2QU1rU4krI6oYDDdERHos+k46xmwqnEJBbiDDxC4NMKp9XU6hQHqN4YaISA8JIbDhZDzm/h6jnkJh2SBfBHAKBaoCGG6IiPTMw2wFPvr1PA7FpAAAAhs7YMGAZpxCgaoMhhsiIj3y1800jN8SheSMXBjLDfBZT0+82dKNUyhQlcJwQ0SkB5QqgRV/XsfSw7FQCaCOvQWWD/ZFE2cbqUsjqnQMN0REOi45PRfjt0Tir7gHAIDX/Fwwq08TWJjwf/FUNfEvn4hIh/155R4mb7+AB9kKmBvLMaefF/r5ukhdFpGkGG6IiHSQokCFBQeu4PsTcQCAJs7WWD7IF3VqWEpcGZH0GG6IiHTMrbRsjN0ciQu30wEAw1u7Y2qPRjAx5EzeRADDDRGRTtkTdQef7opGVl4BqpkbYeEAb3Rp7CB1WURaheGGiEgH5CgK8MXeS9j2920AQHN3WywZ6APnamYSV0akfRhuiIi03JXkDIzZFInrKVmQyYCxnepjXKd6MORM3kTFYrghItJSQghs/CsBs3+7jLwCFWpamWDJQB+0rmsvdWlEWo3hhohIC6U/zseUHRfwe3QyAKBDwxr45nVv2FmaSFwZkfYrc7hJTExEfHw8cnJyUKNGDTRp0gQmJvzSERG9qIiEhxi7KRJ3Hj2GkVyGT7o1wtttPGDAmbyJSqRU4ebWrVtYs2YNNm/ejMTERAgh1K8ZGxujXbt2ePfdd/Haa6/BwIBtwUREpaFSCaw9dhNfH7wKpUqgtq05lg/yhbdrNalLI9IpJU4g48ePR9OmTXHt2jXMmjULly5dQnp6OhQKBZKTkxESEoK2bdvi888/R7NmzXDu3LmKrJuISK/cz8zDsA1nMf/AFShVAr28nbF/XFsGG6IyKPGVG2NjY9y4cQM1atQo8lrNmjXRqVMndOrUCTNmzEBISAhu3bqFl156qVyLJSLSRyeupWLC1iikZuXB1MgAM3s3QVCAK2fyJiojmfh321IVkJGRARsbG6Snp8Pa2lrqcoioCstXqrA4NBarw25ACKChgxVWDPZFfQcrqUsj0jql+f1+4bulUlNT8ddff0GpVOKll16Ck5PTi+6SiEjv3X6Yg3GbIxGR8AgAMLhFbUzv2RimRpxCgehFvVCv3x07dqBevXqYOXMmZsyYgbp162LDhg2l2seqVavg4eEBU1NT+Pv74/jx489cPy8vD59++inc3NxgYmKCunXrYv369S9yGERElepAdBJ6LD2OiIRHsDI1xMrBfviqX1MGG6JyUqorN1lZWbC0/P+MszNnzsTZs2fRoEEDAMD+/fsxcuRIvPXWWyXa39atWzFhwgSsWrUKbdq0wdq1a9G9e3dcvnwZtWvXLnaboKAg3Lt3D+vWrUO9evWQkpKCgoKC0hwGEZEkcvOVmLM/Bj+fuQUA8HGthuWDfOFqay5xZUT6pVRXbvz9/bFnzx71c0NDQ6SkpKif37t3D8bGxiXe36JFizBixAi888478PT0xJIlS+Dq6orVq1cXu/6BAwcQFhaGkJAQdO7cGe7u7mjevDlat25dmsMgIqp011My0XflSXWwGdW+LraPasVgQ1QBShVu/vjjD6xduxb9+vXD3bt3sXTpUgQHB8PR0RH29vaYMmUKVq1aVaJ9KRQKhIeHIzAwUGN5YGAgTp06Vew2e/fuRUBAABYsWIBatWqhQYMGmDx5Mh4/fvzU98nLy0NGRobGg4iosgghsO3vRPRafhJXkjNhZ2GMH99ujindG8GIc0MRVYhSNUu5u7sjJCQEmzZtQvv27TF+/Hhcv34d169fh1KpRKNGjWBqalqifaWmpkKpVMLBwUFjuYODA5KTk4vd5ubNmzhx4gRMTU2xa9cupKam4oMPPsCDBw+e2u9m7ty5mDlzZmkOk4ioXGTlFeDz3dHYFXkHANCmnh0WB/mgpnXJ/j9JRGVTpn82DB48GGfPnkVkZCQ6dOgAlUoFHx+fEgebf/vvOA5CiKeO7aBSqSCTybBx40Y0b94cPXr0wKJFi/DDDz889erN1KlTkZ6ern4kJiaWukYiotK6dDcdvZefwK7IO5AbyPBR14b46e0WDDZElaDUt4L//vvvuHz5Mry9vbFu3TocPXoUgwcPRo8ePTBr1iyYmZmVaD/29vaQy+VFrtKkpKQUuZrzhJOTE2rVqgUbGxv1Mk9PTwghcPv2bdSvX7/INiYmJpzziogqjRACv/wzk7eiQAUnG1MsG+SLl9xtpS6NqMoo1ZWbjz/+GMOHD8e5c+fw3nvvYfbs2ejQoQMiIyNhYmICHx8f/P777yXal7GxMfz9/REaGqqxPDQ09KkdhNu0aYO7d+8iKytLvSw2NhYGBgZwcXEpzaEQEZW79Mf5GL0pAp/vjoaiQIVXGtVEyLh2DDZElaxUIxTb29vjjz/+gL+/Px48eICWLVsiNjZW/fqlS5fw3nvv4cSJEyXa39atW/Hmm29izZo1aNWqFb799lt89913uHTpEtzc3DB16lTcuXMHP/30E4DCW9E9PT3RsmVLzJw5E6mpqXjnnXfQvn17fPfddyV6T45QTEQV4XziI4zZHIHEB/+fyXtEWw9OoUBUTipshGJzc3PExcXB398fiYmJRfrYNGnSpMTBBgCCg4ORlpaGWbNmISkpCV5eXggJCYGbmxsAICkpCQkJCer1LS0tERoairFjxyIgIAB2dnYICgrCl19+WZrDICIqN0IIrDsRh/kHriBfKeBqa4blg/zgwwkviSRTqis3GzduxMiRI1GtWjXk5OTgxx9/RJ8+fSqyvnLHKzdEVF4eZisweft5HL5SON5Xj6aOmPdaM1ibGklcGZH+Kc3vd6knzkxLS8PNmzdRv359VKtW7UXqlATDDRGVh3PxDzBucySS0nNhbGiA6T0bY0iL2myGIqogFTpxpp2dHezs7MpcHBGRLlOpBFaH3cCi0FgoVQJ17C2wYrAfGjvzH0tE2qLEd0uNGjWqxGPEbN26FRs3bixzUURE2uh+Zh6GbTiLhX9chVIl0M+3FvaNbctgQ6RlSnzlpkaNGvDy8kLr1q3Ru3dvBAQEwNnZGaampnj48CEuX76MEydOYMuWLahVqxa+/fbbiqybiKhSnbyeivFbopCalQczIzlm9WmCAf4ubIYi0kKl6nOTkpKCdevWYcuWLYiOjtZ4zcrKCp07d8a7775bZL4obcI+N0RUGgVKFZYdvoblR65DCKChgxVWDPZFfQcrqUsjqlIqtEPxE48ePcKtW7fw+PFj2Nvbo27dujrxLxiGGyIqqeT0XIzbEomzcQ8AAIOau2J6zyYwM5ZLXBlR1VOhHYqfqFatmk7eLUVEVBJHrqRg4rYoPMzJh4WxHF/1b4o+PrWkLouISqDM4YaISB/lK1VY+MdVfHvsJgCgibM1Vgz2g4e9hcSVEVFJMdwQEf0j8UEOxm6ORFTiIwDA8NbumNqjEUwM2QxFpEsYboiIAByITsLHv15ARm4BrE0NsWCAN7p5OUpdFhGVAcMNEVVpuflKzA2JwY+nbwEAfFyrYfkgX7jamktcGRGVVZnDTUFBAY4ePYobN25g8ODBsLKywt27d2FtbQ1LS8vyrJGIqELEpWZjzKYIXLqbAQB4r30dTA5sCCN5icc3JSItVKZwc+vWLXTr1g0JCQnIy8tDly5dYGVlhQULFiA3Nxdr1qwp7zqJiMrVnqg7mLbzIrIVSthaGOObIG90bFhT6rKIqByU6Z8n48ePR0BAAB4+fAgzMzP18n79+uHw4cPlVhwRUXl7rFBiyo4LGL8lCtkKJZp72CJkXDsGGyI9UqYrNydOnMDJkydhbGyssdzNzQ137twpl8KIiMrbtXuZGL0pArH3siCTAWM71ce4TvVgyGYoIr1SpnCjUqmgVCqLLL99+zasrDgkORFpFyEEtoffxvQ90cjNV6GGlQmWBvugdT17qUsjogpQpn+udOnSBUuWLFE/l8lkyMrKwowZM9CjR4/yqo2I6IVl5RVg4rbz+PjXC8jNV6FdfXuEjGvHYEOkx8o0t9Tdu3fRsWNHyOVyXLt2DQEBAbh27Rrs7e1x7Ngx1KypvW3XnFuKqOq4dDcdYzdF4mZqNuQGMkwKbIBRL9eFgYH2z4NHRJoqfG4pZ2dnREVFYcuWLQgPD4dKpcKIESMwZMgQjQ7GRERSEELgl78SMPu3y1AUqOBkY4rlg3wR4G4rdWlEVAnKPCu4ruKVGyL9lv44H1N3XkDIxWQAQGfPmlg4wBvVLYyfsyURabMKv3Izd+5cODg44O2339ZYvn79ety/fx+ffPJJWXZLRPRCzic+wpjNEUh88BhGchmmdPfE223cIZOxGYqoKilTh+K1a9eiUaNGRZY3adKEA/gRUaUTQuD74zcxYM0pJD54DFdbM/w6qjVGtPVgsCGqgsp05SY5ORlOTk5FlteoUQNJSUkvXBQRUUk9zFZg8vbzOHwlBQDQo6kj5r3WDNamRhJXRkRSKVO4cXV1xcmTJ+Hh4aGx/OTJk3B2di6XwoiInudc/AOM2xyJpPRcGBsaYHrPxhjSojav1hBVcWUKN++88w4mTJiA/Px8dOrUCQBw+PBhfPzxx5g0aVK5FkhE9F8qlcDqsBtYFBoLpUqgTg0LrBjkh8bOvEmAiMoYbj7++GM8ePAAH3zwARQKBQDA1NQUn3zyCaZOnVquBRIR/VtqVh4+3BqF49dSAQD9fWthdl8vWJiU6X9nRKSHXuhW8KysLMTExMDMzAz169eHiYlJedZWIXgrOJHuOnMzDeM2RyIlMw+mRgaY3ccLrwe4Sl0WEVWCCr8V/AlLS0u89NJLL7ILIqLnUqkEVh29jkWhsVAJoH5NS6wc4ocGDpzLjoiKKlO4yc7Oxrx583D48GGkpKRApVJpvH7z5s1yKY6I6L/NUAP8XTCrTxOYG7MZioiKV+YOxWFhYXjzzTfh5OTEOxOIqEKcvpGG8VsKm6HMjOSY3dcLA/xdpC6LiLRcmcLN77//jv3796NNmzblXQ8REZQqgZVHrmPJof83Q60a4of6bIYiohIoU7ipXr06bG05AR0Rlb/7mYXNUCeuFzZDve7vgplshiKiUijT9AuzZ8/G9OnTkZOTU971EFEVdupGKnosO44T11NhZiTHN697Y+Hr3gw2RFQqZfo/xjfffIMbN27AwcEB7u7uMDLSHOY8IiKiXIojoqpBqRJY8ed1LD1c2AzVwMESKwezGYqIyqZM4aZv377lXAYRVVX3M/MwYWskTl5PAwAEBbhgZm8vmBnLJa6MiHTVCw3ip4s4iB+R9jh1PRXjt0bh/j93Q83p54X+frwbioiKqrRB/IiIykKpElj+5zUsPXwNQgANHaywcogv6tVkMxQRvbgyhRulUonFixdj27ZtSEhIUM8v9cSDBw/KpTgi0j8pmbmYsCUKp24UNkMFB7jii95N2AxFROWmTHdLzZw5E4sWLUJQUBDS09MxceJE9O/fHwYGBvjiiy/KuUQi0henrqeix9ITOHUjDebGciwO9sb8Ac0YbIioXJWpz03dunWxbNkyvPrqq7CyskJUVJR62ZkzZ7Bp06aKqLVcsM8NUeVTqgSWHb6GZX/+uxnKD/VqWkpdGhHpiArvc5OcnIymTZsCKJw8Mz09HQDQs2dPfP7552XZJRHpqZTMXIzfHIXTNwuboQa+5IoZvdgMRUQVp0zNUi4uLkhKSgIA1KtXDwcPHgQAnDt3DiYmJuVXHRHptBPXUtFj6XGcvvn/Zqh5r7EZiogqVpmu3PTr1w+HDx9GixYtMH78eAwaNAjr1q1DQkICPvzww/KukYh0jFIlsPTwNSz/pxmqkaMVVgxmMxQRVY5yGefmzJkzOHXqFOrVq4fevXuXR10Vhn1uiCpWSkYuxm/5fzPUoOaFzVCmRrxaQ0RlV+nj3LRs2RItW7Ysj10RkQ47cS0VE7ZGIjVLAXNjOb7q1xR9fWtJXRYRVTElDjd79+5F9+7dYWRkhL179z5zXW2/ekNE5UupElh6KBbLj1xXN0OtHOKHujXYDEVEla/EzVIGBgZITk5GzZo1YWDw9H7IMpkMSqWy3Aosb2yWIipf9zJyMW5zJP6KKxy8c1Dz2pjRqzGboYioXFVIs5RKpSr2v4mo6joWex8fbo1CWrYCFsZyfNW/Kfr4sBmKiKRV6lvB8/Pz0bFjR8TGxlZEPUSkAwqUKnxz8CqGbTiLtGwFGjlaYe/Ytgw2RKQVSt2h2MjICNHR0ZDJZBVRDxFpuf82Qw1uURvTe7IZioi0R5kG8Rs6dCjWrVtX3rUQkZY7FnsfPZYex19xD2BhLMfSgT74ql9TBhsi0ipluhVcoVDg+++/R2hoKAICAmBhYaHx+qJFi8qlOCLSDgVKFZYcuoaVRwvvhvJ0ssbKwb6ow7uhiEgLlSncREdHw8/PDwCK9L1hcxWRfklOL2yGOhvPZigi0g1lCjdHjhwp7zqISAuF/XM31IN/7oaa+1oz9PZ2lrosIqJnKpcRiolIvxQoVVh8KBYrj9wAUNgMtWqIHzzsLZ6zJRGR9Mocbs6dO4ft27cjISEBCoVC47WdO3e+cGFEJI3/NkMNaVEbn7MZioh0SJnultqyZQvatGmDy5cvY9euXcjPz8fly5fx559/wsbGplT7WrVqFTw8PGBqagp/f38cP368RNudPHkShoaG8PHxKcMREFFxjsXex6vLjuNs/ANYmhhi+SBfzOHdUESkY8oUbr766issXrwYv/32G4yNjbF06VLExMQgKCgItWvXLvF+tm7digkTJuDTTz9FZGQk2rVrh+7duyMhIeGZ26Wnp2Po0KF45ZVXylI+Ef2HUiWw6F+D8nk6WWPf2Lboxf41RKSDSjy31L9ZWFjg0qVLcHd3h729PY4cOYKmTZsiJiYGnTp1QlJSUon206JFC/j5+WH16tXqZZ6enujbty/mzp371O0GDhyI+vXrQy6XY/fu3YiKiipx7ZxbikhTSmYuxm+OwumbaQA4NxQRaafS/H6X6cqNra0tMjMzAQC1atVCdHQ0AODRo0fIyckp0T4UCgXCw8MRGBiosTwwMBCnTp166nYbNmzAjRs3MGPGjLKUTkT/cupGKl5ddgKnb6bBzEiOxcHemNufzVBEpNvK1KG4Xbt2CA0NRdOmTREUFITx48fjzz//RGhoaImbilJTU6FUKuHg4KCx3MHBAcnJycVuc+3aNUyZMgXHjx+HoWHJSs/Ly0NeXp76eUZGRom2I9JnKpXAyiPXsfhQLFQCaOBgiVVD/FCvppXUpRERvbBShZuoqCj4+PhgxYoVyM3NBQBMnToVRkZGOHHiBPr374/PP/+8VAX8d9A/IUSxAwEqlUoMHjwYM2fORIMGDUq8/7lz52LmzJmlqolIn6Vl5WHC1igcv5YKABjg74JZfZrA3JgjQxCRfihVnxsDAwP4+vrinXfeweDBg0t9Z9S/KRQKmJubY/v27ejXr596+fjx4xEVFYWwsDCN9R89eoTq1atDLv//5XKVSgUhBORyOQ4ePIhOnToVeZ/irty4urqyzw1VSefiH2DspkgkZ+TC1MgAs/p4ISjAVeqyiIieq8L63Jw8eRJ+fn6YMmUKnJyc8MYbb5R5tGJjY2P4+/sjNDRUY3loaChat25dZH1ra2tcvHgRUVFR6seoUaPQsGFDREVFoUWLFsW+j4mJCaytrTUeRFWNSiWwJuwGBn57BskZuahTwwK7R7dhsCEivVSq69CtWrVCq1atsGzZMmzbtg0bNmxA586d4e7ujrfffhvDhg2Di4tLifc3ceJEvPnmmwgICECrVq3w7bffIiEhAaNGjQJQ2OR1584d/PTTTzAwMICXl5fG9jVr1oSpqWmR5UT0fw+zFZi0/Tz+vJICAOjj44w5/ZrC0oTNUESkn8p0t5SZmRmGDRuGo0ePIjY2FoMGDcLatWvh4eGBHj16lHg/wcHBWLJkCWbNmgUfHx8cO3YMISEhcHNzAwAkJSU9d8wbInq6iISH6Ln8BP68kgJjQwPM6eeFJcE+DDZEpNfKNM7Nf2VlZWHjxo2YNm0aHj16BKVSWR61VQiOc0NVgRAC60/GY25IDApUAu525lgx2A9etcreT46ISEql+f1+oX++hYWFYf369dixYwfkcjmCgoIwYsSIF9klEb2g9Mf5+PjX8/jj0j0AQI+mjpj3WjNYmxpJXBkRUeUodbhJTEzEDz/8gB9++AFxcXFo3bo1li9fjqCgIFhYcMZgIildvJ2ODzaFI/HBYxjJZfi0hyeGtXYvdngFIiJ9Vapw06VLFxw5cgQ1atTA0KFD8fbbb6Nhw4YVVRsRlZAQAj+fuYUvf4uBQqmCS3UzrBzsB2/XalKXRkRU6UoVbszMzLBjxw707NlTY7wZIpJOZm4+puy8iP0XCud069LYAV8P8IaNOZuhiKhqKlW42bt3b0XVQURlcPluBkZvikBcajYMDWSY0r0RRrT1YDMUEVVpvB+USAcJIbDlXCK+2HsJeQUqONmYYsVgP/i7VZe6NCIiyTHcEOmY7LwCfLY7Grsi7wAAOjSsgUVBPrC1MJa4MiIi7cBwQ6RDYu9l4oONEbiekgW5gQyTAhtg1Mt1YWDAZigioicYboh0xK/ht/H57mg8zleippUJlg/yRYs6dlKXRUSkdRhuiLTcY4USM/ZGY9vftwEAbevZY8lAH9hbmkhcGRGRdmK4IdJiN+5n4YNfInD1XiZkMmDCKw0wplM9yNkMRUT0VAw3RFpqT9QdTNt5EdkKJewtjbF0oC/a1LOXuiwiIq3HcEOkZXLzlZj922Vs/CsBANCyji2WDfRFTWtTiSsjItINDDdEWiQ+NRujN0Xg0t0MAMDYTvUw/pX6MJQbSFwZEZHuYLgh0hK/X0zCx79eQGZeAaqbG2FxsA86NKwpdVlERDqH4YZIYooCFb4KicEPp+IBAAFu1bF8sC+cbMykLYyISEcx3BBJKPFBDsZsisD52+kAgPfa18HkwIYwYjMUEVGZMdwQSeTQ5XuYuC0KGbkFsDEzwqIgb7zi6SB1WUREOo/hhqiSFShVWHjwKtaG3QQAeLtWw8rBvnCpbi5xZURE+oHhhqgS3cvIxdhNkTgb/wAAMLy1O6b18ISxIZuhiIjKC8MNUSU5dT0V47ZEIjVLAUsTQ8x/rRlebeYkdVlERHqH4YaogqlUAiuPXMfiQ7FQCaCRoxVWDfFDnRqWUpdGRKSXGG6IKtCDbAU+3BqFsNj7AICgABfM6uMFUyO5xJUREekvhhuiChKR8BBjNkbgbnouTAwNMLuvF4ICXKUui4hI7zHcEJUzIQQ2nIzHVyExKFAJeNhbYNUQP3g6WUtdGhFRlcBwQ1SOMnPz8cmOCwi5mAwA6NHUEfNfawYrUyOJKyMiqjoYbojKyeW7GfhgYzji03JgJJdhWg9PDG/tDplMJnVpRERVCsMNUTnYdi4Rn++JRl6BCs42plg5xA++tatLXRYRUZXEcEP0Ah4rlPh8TzR+Db8NAOjQsAYWB/mguoWxxJUREVVdDDdEZXTzfhY+2BiBK8mZMJABE7s0wAcd6sHAgM1QRERSYrghKoP9F5LwyY4LyMorgL2lMZYN8kXruvZSl0VERGC4ISoVRYEKX4XE4IdT8QCA5h62WD7IFw7WptIWRkREagw3RCV059FjjN4YgajERwCAUe3rYnJgAxjKOeklEZE2YbghKoEjV1Pw4dYoPMrJh7WpIRYF+aBzYwepyyIiomIw3BA9Q4FShcWHYrHyyA0AQDMXG6wc7AdXW3OJKyMioqdhuCF6ipTMXIzfHIXTN9MAAG+2dMNnPT1hYshJL4mItBnDDVExztxMw9jNkbifmQdzYznm9m+KPj61pC6LiIhKgOGG6F9UKoG1x25i4R9XoBJAAwdLrBrij3o1LaUujYiISojhhugfj3IUmLTtPA5fSQEA9PethS/7ecHcmF8TIiJdwv9rEwE4n/gIH2yMwJ1Hj2FsaICZvZtg4EuunPSSiEgHMdxQlSaEwC9nbmH2bzFQKFVwszPHysF+8KplI3VpRERURgw3VGVl5RVg6s6L2Hf+LgAgsLEDFr7uDRszI4krIyKiF8FwQ1VS7L1MjPolHDfvZ8PQQIYp3RthRFsPNkMREekBhhuqcnZG3Manu6LxOF8JR2tTrBjsiwB3W6nLIiKicsJwQ1VGbr4SM/ddwuaziQCAdvXtsSTYB3aWJhJXRkRE5YnhhqqEW2nZeP+XCFxOyoBMBox/pT7GdqoPuQGboYiI9A3DDem9A9HJ+OjX88jMLYCthTGWDvRBu/o1pC6LiIgqCMMN6a18pQrzf7+C70/EAQD83apjxWBfONmYSVwZERFVJIYb0kvJ6bkYvSkC4bceAgBGtvPAx90awUhuIHFlRERU0RhuSO+cvJ6KcZsjkZatgJWJIRa+7o1uXo5Sl0VERJWE4Yb0hkolsOrodSwKjYVKAJ5O1ljzhh/c7CykLo2IiCoRww3phUc5Ckzcdh5//jPpZVCAC2b18YKpkVziyoiIqLIx3JDOu3C7cNLL2w8fw8TQALP7eCHoJVepyyIiIokw3JDOEkJg09kEzNx7GQqlCrVtzbH6DT80ceakl0REVRnDDemkxwolPt11ETsj7wAAOns64JsgTnpJREQMN6SDbt7Pwvu/RODqvUwYyICPuzXCey/X4aSXREQEgOGGdMzvF5Pw0a8XkJVXAHtLEywf5ItWde2kLouIiLSI5COarVq1Ch4eHjA1NYW/vz+OHz/+1HV37tyJLl26oEaNGrC2tkarVq3wxx9/VGK1JJV8pQqzf7uM9zdGICuvAM3dbREyri2DDRERFSFpuNm6dSsmTJiATz/9FJGRkWjXrh26d++OhISEYtc/duwYunTpgpCQEISHh6Njx47o1asXIiMjK7lyqkzJ6bkY9O0ZrPtnGoV3X66DjSNboKa1qcSVERGRNpIJIYRUb96iRQv4+flh9erV6mWenp7o27cv5s6dW6J9NGnSBMHBwZg+fXqJ1s/IyICNjQ3S09NhbW1dprqp8py6UTjacGoWRxsmIqrKSvP7LVmfG4VCgfDwcEyZMkVjeWBgIE6dOlWifahUKmRmZsLW1vap6+Tl5SEvL0/9PCMjo2wFU6VSqQRWh93ANwevQiWARo5WWP2GPzzsOdowERE9m2TNUqmpqVAqlXBwcNBY7uDggOTk5BLt45tvvkF2djaCgoKeus7cuXNhY2Ojfri6cnA3bZeek4+RP/2NhX8UBpsB/i7Y9UEbBhsiIioRyTsU//f2XSFEiW7p3bx5M7744gts3boVNWvWfOp6U6dORXp6uvqRmJj4wjVTxYm+k46eK47j8JUUGBsaYF7/plg4oBnMjDmNAhERlYxkzVL29vaQy+VFrtKkpKQUuZrzX1u3bsWIESOwfft2dO7c+ZnrmpiYwMTE5IXrpYolhMCWc4mYsfcSFAUquNqaYfUQf3jV4mjDRERUOpJduTE2Noa/vz9CQ0M1loeGhqJ169ZP3W7z5s0YPnw4Nm3ahFdffbWiy6RK8FihxOTtFzB150UoClTo7FkTv41px2BDRERlIukgfhMnTsSbb76JgIAAtGrVCt9++y0SEhIwatQoAIVNSnfu3MFPP/0EoDDYDB06FEuXLkXLli3VV33MzMxgY8MfQl0Ul5qN938Jx5XkwtGGJwU2xPvt68LAgKMNExFR2UgaboKDg5GWloZZs2YhKSkJXl5eCAkJgZubGwAgKSlJY8ybtWvXoqCgAKNHj8bo0aPVy4cNG4YffvihssunF3QgOhkfbT+PzLwC2FsaY9kgX7Suay91WUREpOMkHedGChznRnr5ShUW/nEV3x67CQAIcKuOFYP94GjDQfmIiKh4OjHODVVNKRm5GLMpEmfjHwAA3mnrgU+6N4KRXPIb94iISE8w3FClOX0jDWM3RyI1Kw+WJoZYOKAZujd1krosIiLSMww3VOGEEFgTdhML/7gClQAaOlhh9Rt+qFPDUurSiIhIDzHcUIVKf5yPSdvO41DMPQBAf99a+LKfF8yN+adHREQVg78wVGEu3U3H+79EIOFBDozlBviidxMMau5aohGoiYiIyorhhirE1nMJ+HxP4WjDtaqZYfUbfmjmUk3qsoiIqApguKFylZuvxPQ90dj2920AQMeGNbA42AfVzI0lroyIiKoKhhsqN7fSsvH+LxG4nJQBAxkwsUsDfNChHkcbJiKiSsVwQ+Ui9PI9TNwWhczcAthZFI423KYeRxsmIqLKx3BDL6RAqcI3obFYffQGAMDfrTpWDPaFk42ZxJUREVFVxXBDZZaalYdxmyNx6kYaAOCtNu6Y2t0TxoYcbZiIiKTDcENlEpHwEKM3RiApPRfmxnLMe60Zens7S10WERERww2VjhACP5+5hdm/XUa+UqBODQusecMfDRyspC6NiIgIAMMNlUKOogCf7orGrsg7AIDuXo5YMKAZrEyNJK6MiIjo/xhuqETiUrPx/i/huJKcCbmBDFO6NcI77Tw42jAREWkdhht6rj8uJWPytvPIzCuAvaUJVgz2Rcs6dlKXRUREVCyGG3qqAqUKXx+MxZqwwtu8A9yqY+UQPzhYm0pcGRER0dMx3FCx/nub99ttPDC1RyMYyXmbNxERaTeGGyoi/Fbhbd7JGYW3ec9/rRl68TZvIiLSEQw3pCaEwE+nb+HL/YW3edf95zbv+rzNm4iIdAjDDQEovM172s6L2B11FwDQo6kjFgzwhqUJ/0SIiEi38JeLcPN+Ft7/JQJX7xXe5j21eyOMaMvbvImISDcx3FRxB6KT8dH2wtu8a1iZYMUgX7Tgbd5ERKTDGG6qqP/e5v2Se3WsHOyHmrzNm4iIdBzDTRV0P7PwNu/TNwtv8x7R1gNTuvM2byIi0g8MN1VM+K2H+GBjOO5l5MHcWI4FA5qhZzPe5k1ERPqD4aaK4G3eRERUVTDcVAE5igJM3XkRe/65zfvVpk6YP6AZb/MmIiK9xF83PXfzfhZG/RKO2HtZvM2biIiqBIYbPXYgOhmTt59H1j+3ea8c7IfmHrZSl0VERFShGG70UIFShYUHr2Jt2E0AQHN3W6wY7MvbvImIqEpguNEzvM2biIiqOoYbPRJ+6wE+2BiBexl5sDCWY8EAb7zazEnqsoiIiCoVw40eEELgx1Px+HJ/DApUAvVqWmLNG36oV5O3eRMRUdXDcKPjchQFmLLjIvae523eREREAMONTotLzcaon8Nx9V4mDA1kmNrDE2+3cedt3kREVKUx3OioQ5fv4cOtUerZvHmbNxERUSGGGx2jVAksORSL5X9eBwAEuFXHqiGczZuIiOgJhhsd8ihHgfFbohAWex8AMLy1O6b18ISxIW/zJiIieoLhRkdcupuOUb+EI/HBY5gaGWBu/6bo5+sidVlERERah+FGB+yMuI2pOy8ir0AFV1szrH0jAI2draUui4iISCsx3GgxRYEKX+6/jJ9O3wIAtG9QA0sH+qCaubHElREREWkvhhstdS8jFx9sjED4rYcAgHGd6mF85waQG/A2byIiomdhuNFCZ+MeYPSmCNzPzIOVqSEWB/mgc2MHqcsiIiLSCQw3WkQIgR9OxWPOP9MoNHSwwpo3/eFhbyF1aURERDqD4UZLPFYoMWXnBeyJKpxGoZe3M+a/1hTmxjxFREREpcFfTi1wKy0b7/0cjivJmZAbyDCN0ygQERGVGcONxI5cScH4LZHIyC2AvaUxVgz2Q8s6dlKXRUREpLMYbiSiUgks+/Malh6+BiEA39rVsHqIPxxtOI0CERHRi2C4kUB6Tj4+3BaFP6+kAADeaFkbn/dsDBNDucSVERER6T6Gm0oWk5SBUb+E41ZaDowNDTCnrxdeD3CVuiwiIiK9wXBTifZE3cEnOy4gN1+FWtXMsPZNf3jVspG6LCIiIr3CcFMJ8pUqfBUSgw0n4wEA7erbY9lAX1S34DQKRERE5Y3hpoKlZOZizMZInI1/AAAY3bEuJnZpyGkUiIiIKgjDTQUKv/UA7/8SgZTMPFiaGOKbIG90beIodVlERER6jeGmAggh8POZW5j922XkKwXq17TEmjf9UbeGpdSlERER6T2Gm3KWm6/EtF0XsTPiDgCgR1NHLBjgDUsTftRERESVwUDqAlatWgUPDw+YmprC398fx48ff+b6YWFh8Pf3h6mpKerUqYM1a9ZUUqXPl/ggB/1XncLOiDswkAHTejTCysF+DDZERESVSNJws3XrVkyYMAGffvopIiMj0a5dO3Tv3h0JCQnFrh8XF4cePXqgXbt2iIyMxLRp0zBu3Djs2LGjkisvKjLhIXouP4HLSRmwtTDGLyNa4N2X63J+KCIiokomE0IIqd68RYsW8PPzw+rVq9XLPD090bdvX8ydO7fI+p988gn27t2LmJgY9bJRo0bh/PnzOH36dIneMyMjAzY2NkhPT4e1tfWLH8Q/0nPy0WvFCVS3MMbqIX5wrmZWbvsmIiKq6krz+y1Ze4lCoUB4eDimTJmisTwwMBCnTp0qdpvTp08jMDBQY1nXrl2xbt065Ofnw8jIqMg2eXl5yMvLUz/PyMgoh+qLsjE3wsZ3WqCmtQmnUSAiIpKQZM1SqampUCqVcHBw0Fju4OCA5OTkYrdJTk4udv2CggKkpqYWu83cuXNhY2Ojfri6VtxUB6625gw2REREEpO8Q/F/+6QIIZ7ZT6W49Ytb/sTUqVORnp6ufiQmJr5gxURERKTNJGuWsre3h1wuL3KVJiUlpcjVmSccHR2LXd/Q0BB2dnbFbmNiYgITE5PyKZqIiIi0nmRXboyNjeHv74/Q0FCN5aGhoWjdunWx27Rq1arI+gcPHkRAQECx/W2IiIio6pG0WWrixIn4/vvvsX79esTExODDDz9EQkICRo0aBaCwSWno0KHq9UeNGoVbt25h4sSJiImJwfr167Fu3TpMnjxZqkMgIiIiLSPp6HLBwcFIS0vDrFmzkJSUBC8vL4SEhMDNzQ0AkJSUpDHmjYeHB0JCQvDhhx9i5cqVcHZ2xrJly/Daa69JdQhERESkZSQd50YKFTXODREREVWc0vx+S363FBEREVF5YrghIiIivcJwQ0RERHqF4YaIiIj0CsMNERER6RWGGyIiItIrDDdERESkVyQdxE8KT4b1ycjIkLgSIiIiKqknv9slGZ6vyoWbzMxMAICrq6vElRAREVFpZWZmwsbG5pnrVLkRilUqFe7evQsrKyvIZLJy3XdGRgZcXV2RmJiot6Mf6/sx6vvxATxGfaDvxwfo/zHq+/EB5X+MQghkZmbC2dkZBgbP7lVT5a7cGBgYwMXFpULfw9raWm//WJ/Q92PU9+MDeIz6QN+PD9D/Y9T34wPK9xifd8XmCXYoJiIiIr3CcENERER6heGmHJmYmGDGjBkwMTGRupQKo+/HqO/HB/AY9YG+Hx+g/8eo78cHSHuMVa5DMREREek3XrkhIiIivcJwQ0RERHqF4YaIiIj0CsMNERER6RWGm3KyatUqeHh4wNTUFP7+/jh+/LjUJZXZ3Llz8dJLL8HKygo1a9ZE3759cfXqVY11hg8fDplMpvFo2bKlRBWXzhdffFGkdkdHR/XrQgh88cUXcHZ2hpmZGTp06IBLly5JWHHpubu7FzlGmUyG0aNHA9DN83fs2DH06tULzs7OkMlk2L17t8brJTlveXl5GDt2LOzt7WFhYYHevXvj9u3blXgUT/es48vPz8cnn3yCpk2bwsLCAs7Ozhg6dCju3r2rsY8OHToUOa8DBw6s5CN5uuedw5L8XWrzOQSef4zFfS9lMhkWLlyoXkebz2NJfh+04bvIcFMOtm7digkTJuDTTz9FZGQk2rVrh+7duyMhIUHq0sokLCwMo0ePxpkzZxAaGoqCggIEBgYiOztbY71u3bohKSlJ/QgJCZGo4tJr0qSJRu0XL15Uv7ZgwQIsWrQIK1aswLlz5+Do6IguXbqo5yXTBefOndM4vtDQUADA66+/rl5H185fdnY2vL29sWLFimJfL8l5mzBhAnbt2oUtW7bgxIkTyMrKQs+ePaFUKivrMJ7qWceXk5ODiIgIfP7554iIiMDOnTsRGxuL3r17F1l35MiRGud17dq1lVF+iTzvHALP/7vU5nMIPP8Y/31sSUlJWL9+PWQyGV577TWN9bT1PJbk90ErvouCXljz5s3FqFGjNJY1atRITJkyRaKKyldKSooAIMLCwtTLhg0bJvr06SNdUS9gxowZwtvbu9jXVCqVcHR0FPPmzVMvy83NFTY2NmLNmjWVVGH5Gz9+vKhbt65QqVRCCN0+f0IIAUDs2rVL/bwk5+3Ro0fCyMhIbNmyRb3OnTt3hIGBgThw4ECl1V4S/z2+4pw9e1YAELdu3VIva9++vRg/fnzFFldOijvG5/1d6tI5FKJk57FPnz6iU6dOGst06Tz+9/dBW76LvHLzghQKBcLDwxEYGKixPDAwEKdOnZKoqvKVnp4OALC1tdVYfvToUdSsWRMNGjTAyJEjkZKSIkV5ZXLt2jU4OzvDw8MDAwcOxM2bNwEAcXFxSE5O1jifJiYmaN++vc6eT4VCgV9++QVvv/22xmSxunz+/qsk5y08PBz5+fka6zg7O8PLy0snz216ejpkMhmqVaumsXzjxo2wt7dHkyZNMHnyZJ264gg8++9S387hvXv3sH//fowYMaLIa7pyHv/7+6At38UqN3FmeUtNTYVSqYSDg4PGcgcHByQnJ0tUVfkRQmDixIlo27YtvLy81Mu7d++O119/HW5uboiLi8Pnn3+OTp06ITw8XOtH3GzRogV++uknNGjQAPfu3cOXX36J1q1b49KlS+pzVtz5vHXrlhTlvrDdu3fj0aNHGD58uHqZLp+/4pTkvCUnJ8PY2BjVq1cvso6ufVdzc3MxZcoUDB48WGNCwiFDhsDDwwOOjo6Ijo7G1KlTcf78eXWzpLZ73t+lPp1DAPjxxx9hZWWF/v37ayzXlfNY3O+DtnwXGW7Kyb//RQwUnvT/LtNFY8aMwYULF3DixAmN5cHBwer/9vLyQkBAANzc3LB///4iX1Rt0717d/V/N23aFK1atULdunXx448/qjsv6tP5XLduHbp37w5nZ2f1Ml0+f89SlvOma+c2Pz8fAwcOhEqlwqpVqzReGzlypPq/vby8UL9+fQQEBCAiIgJ+fn6VXWqplfXvUtfO4RPr16/HkCFDYGpqqrFcV87j034fAOm/i2yWekH29vaQy+VF0mZKSkqR5Kprxo4di7179+LIkSNwcXF55rpOTk5wc3PDtWvXKqm68mNhYYGmTZvi2rVr6rum9OV83rp1C4cOHcI777zzzPV0+fwBKNF5c3R0hEKhwMOHD5+6jrbLz89HUFAQ4uLiEBoaqnHVpjh+fn4wMjLS2fP6379LfTiHTxw/fhxXr1597ncT0M7z+LTfB235LjLcvCBjY2P4+/sXuVwYGhqK1q1bS1TVixFCYMyYMdi5cyf+/PNPeHh4PHebtLQ0JCYmwsnJqRIqLF95eXmIiYmBk5OT+lLwv8+nQqFAWFiYTp7PDRs2oGbNmnj11VefuZ4unz8AJTpv/v7+MDIy0lgnKSkJ0dHROnFunwSba9eu4dChQ7Czs3vuNpcuXUJ+fr7Ontf//l3q+jn8t3Xr1sHf3x/e3t7PXVebzuPzfh+05rtYLt2Sq7gtW7YIIyMjsW7dOnH58mUxYcIEYWFhIeLj46UurUzef/99YWNjI44ePSqSkpLUj5ycHCGEEJmZmWLSpEni1KlTIi4uThw5ckS0atVK1KpVS2RkZEhc/fNNmjRJHD16VNy8eVOcOXNG9OzZU1hZWanP17x584SNjY3YuXOnuHjxohg0aJBwcnLSiWP7N6VSKWrXri0++eQTjeW6ev4yMzNFZGSkiIyMFADEokWLRGRkpPpuoZKct1GjRgkXFxdx6NAhERERITp16iS8vb1FQUGBVIel9qzjy8/PF7179xYuLi4iKipK43uZl5cnhBDi+vXrYubMmeLcuXMiLi5O7N+/XzRq1Ej4+vpqxfEJ8exjLOnfpTafQyGe/3cqhBDp6enC3NxcrF69usj22n4en/f7IIR2fBcZbsrJypUrhZubmzA2NhZ+fn4at03rGgDFPjZs2CCEECInJ0cEBgaKGjVqCCMjI1G7dm0xbNgwkZCQIG3hJRQcHCycnJyEkZGRcHZ2Fv379xeXLl1Sv65SqcSMGTOEo6OjMDExES+//LK4ePGihBWXzR9//CEAiKtXr2os19Xzd+TIkWL/LocNGyaEKNl5e/z4sRgzZoywtbUVZmZmomfPnlpz3M86vri4uKd+L48cOSKEECIhIUG8/PLLwtbWVhgbG4u6deuKcePGibS0NGkP7F+edYwl/bvU5nMoxPP/ToUQYu3atcLMzEw8evSoyPbafh6f9/sghHZ8F2X/FEtERESkF9jnhoiIiPQKww0RERHpFYYbIiIi0isMN0RERKRXGG6IiIhIrzDcEBERkV5huCEiIiK9wnBDRGrx8fGQyWSIioqSuhS1K1euoGXLljA1NYWPj4/U5RCRDmC4IdIiw4cPh0wmw7x58zSW7969WydnPS4PM2bMgIWFBa5evYrDhw8/db3k5GSMHTsWderUgYmJCVxdXdGrV69nblMVDR8+HH379pW6DKIKxXBDpGVMTU0xf/78IjPm6jKFQlHmbW/cuIG2bdvCzc3tqZNFxsfHw9/fH3/++ScWLFiAixcv4sCBA+jYsSNGjx5d5vcmIt3EcEOkZTp37gxHR0fMnTv3qet88cUXRZpolixZAnd3d/XzJ/9C/+qrr+Dg4IBq1aph5syZKCgowEcffQRbW1u4uLhg/fr1RfZ/5coVtG7dGqampmjSpAmOHj2q8frly5fRo0cPWFpawsHBAW+++SZSU1PVr3fo0AFjxozBxIkTYW9vjy5duhR7HCqVCrNmzYKLiwtMTEzg4+ODAwcOqF+XyWQIDw/HrFmzIJPJ8MUXXxS7nw8++AAymQxnz57FgAED0KBBAzRp0gQTJ07EmTNn1OslJCSgT58+sLS0hLW1NYKCgnDv3r0in+v69etRu3ZtWFpa4v3334dSqcSCBQvg6OiImjVrYs6cORrvL5PJsHr1anTv3h1mZmbw8PDA9u3bNda5ePEiOnXqBDMzM9jZ2eHdd99FVlZWkfP19ddfw8nJCXZ2dhg9ejTy8/PV6ygUCnz88ceoVasWLCws0KJFC41z88MPP6BatWr4448/4OnpCUtLS3Tr1g1JSUnq4/vxxx+xZ88eyGQyyGQyHD16FAqFAmPGjIGTkxNMTU3h7u7+zL8/Iq1XbrNUEdELGzZsmOjTp4/YuXOnMDU1FYmJiUIIIXbt2iX+/XWdMWOG8Pb21th28eLFws3NTWNfVlZWYvTo0eLKlSti3bp1AoDo2rWrmDNnjoiNjRWzZ88WRkZG6gnrnkzQ6OLiIn799Vdx+fJl8c477wgrKyuRmpoqhBDi7t27wt7eXkydOlXExMSIiIgI0aVLF9GxY0f1e7dv315YWlqKjz76SFy5ckXExMQUe7yLFi0S1tbWYvPmzeLKlSvi448/FkZGRiI2NlYIIURSUpJo0qSJmDRpkkhKShKZmZlF9pGWliZkMpn46quvnvnZqlQq4evrK9q2bSv+/vtvcebMGeHn5yfat2+v8blaWlqKAQMGiEuXLom9e/cKY2Nj0bVrVzF27Fhx5coVsX79egFAnD59Wr0dAGFnZye+++47cfXqVfHZZ58JuVwuLl++LIQQIjs7Wz1J68WLF8Xhw4eFh4eHxmSKw4YNE9bW1mLUqFEiJiZG7Nu3T5ibm4tvv/1Wvc7gwYNF69atxbFjx8T169fFwoULhYmJifrz2rBhgzAyMhKdO3cW586dE+Hh4cLT01MMHjxYCFE4Y3VQUJDo1q2bxqziCxcuFK6uruLYsWMiPj5eHD9+XGzatOmZnyeRNmO4IdIiT8KNEEK0bNlSvP3220KIsocbNzc3oVQq1csaNmwo2rVrp35eUFAgLCwsxObNm4UQ/w838+bNU6+Tn58vXFxcxPz584UQQnz++eciMDBQ470TExM1ZiBv37698PHxee7xOjs7izlz5mgse+mll8QHH3ygfu7t7S1mzJjx1H389ddfAoDYuXPnM9/r4MGDQi6Xa8w8fOnSJQFAnD17VghR+Lmam5uLjIwM9Tpdu3YV7u7uRT7HuXPnqp8DEKNGjdJ4vxYtWoj3339fCCHEt99+K6pXry6ysrLUr+/fv18YGBiI5ORkIcT/z1dBQYF6nddff10EBwcLIYS4fv26kMlk4s6dOxrv88orr4ipU6cKIQrDDQBx/fp19esrV64UDg4O6uf//ht7YuzYsaJTp05CpVI99fMj0iVsliLSUvPnz8ePP/6Iy5cvl3kfTZo0gYHB/7/mDg4OaNq0qfq5XC6HnZ0dUlJSNLZr1aqV+r8NDQ0REBCAmJgYAEB4eDiOHDkCS0tL9aNRo0YACvvHPBEQEPDM2jIyMnD37l20adNGY3mbNm3U71USQggAeG6H65iYGLi6usLV1VW9rHHjxqhWrZrG+7m7u8PKykr93MHBAY0bNy7yOT7rM3vy/Ml+Y2Ji4O3tDQsLC/Xrbdq0gUqlwtWrV9XLmjRpArlcrn7u5OSkfp+IiAgIIdCgQQONzz4sLEzjczc3N0fdunWL3cfTDB8+HFFRUWjYsCHGjRuHgwcPPnN9Im1nKHUBRFS8l19+GV27dsW0adMwfPhwjdcMDAzUP+pP/LtvxhNGRkYaz2UyWbHLVCrVc+t5Eh5UKhV69eqF+fPnF1nHyclJ/d///iEvyX6fEEKU6s6w+vXrQyaTISYm5pl3AT1tv/9dXhGf2bOO6Xnv/eR9VCoV5HI5wsPDNQIQAFhaWj5zH//9W/kvPz8/xMXF4ffff8ehQ4cQFBSEzp0749dff33OERJpJ165IdJic+fOxb59+3Dq1CmN5TVq1EBycrLGj1Z5jk3z7064BQUFCA8PV1+d8fPzw6VLl+Du7o569eppPEoaaADA2toazs7OOHHihMbyU6dOwdPTs8T7sbW1RdeuXbFy5UpkZ2cXef3Ro0cACq/SJCQkIDExUf3a5cuXkZ6eXqr3e5p/f2ZPnj/5zBo3boyoqCiN+k6ePAkDAwM0aNCgRPv39fWFUqlESkpKkc/d0dGxxHUaGxtDqVQWWW5tbY3g4GB899132Lp1K3bs2IEHDx6UeL9E2oThhkiLNWvWDEOGDMHy5cs1lnfo0AH379/HggULcOPGDaxcuRK///57ub3vypUrsWvXLly5cgWjR4/Gw4cP8fbbbwMARo8ejQcPHmDQoEE4e/Ysbt68iYMHD+Ltt98u9kfzWT766CPMnz8fW7duxdWrVzFlyhRERUVh/PjxpdrPqlWroFQq0bx5c+zYsQPXrl1DTEwMli1bpm4u6ty5s/rzjIiIwNmzZzF06FC0b9/+uU1oJbF9+3asX78esbGxmDFjBs6ePYsxY8YAAIYMGQJTU1MMGzYM0dHROHLkCMaOHYs333wTDg4OJdp/gwYNMGTIEAwdOhQ7d+5EXFwczp07h/nz5yMkJKTEdbq7u+PChQu4evUqUlNTkZ+fj8WLF2PLli24cuUKYmNjsX37djg6OqJatWpl+SiIJMdwQ6TlZs+eXaRZwdPTE6tWrcLKlSvh7e2Ns2fPYvLkyeX2nvPmzcP8+fPh7e2N48ePY8+ePbC3twcAODs74+TJk1AqlejatSu8vLwwfvx42NjYaPRLKYlx48Zh0qRJmDRpEpo2bYoDBw5g7969qF+/fqn24+HhgYiICHTs2BGTJk2Cl5cXunTpgsOHD2P16tUACptndu/ejerVq+Pll19G586dUadOHWzdurVU7/U0M2fOxJYtW9CsWTP8+OOP2LhxIxo3bgygsB/MH3/8gQcPHuCll17CgAED8Morr2DFihWleo8NGzZg6NChmDRpEho2bIjevXvjr7/+0uhH9DwjR45Ew4YNERAQgBo1auDkyZOwtLTE/PnzERAQgJdeegnx8fEICQkp9fkk0hYy8bzGWCIieiaZTIZdu3Zx5F8iLcFYTkRERHqF4YaIiIj0Cm8FJyJ6QWzdJ9IuvHJDREREeoXhhoiIiPQKww0RERHpFYYbIiIi0isMN0RERKRXGG6IiIhIrzDcEBERkV5huCEiIiK9wnBDREREeuV/FVCxhW6lrDMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## getting the optimal number of pca\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(df)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731dce12",
   "metadata": {},
   "source": [
    "For selecting the features we used two techniques:\n",
    "1) Checking correlation we used corrmat function but it gaves no such features.\n",
    "\n",
    "2) We applied PCA to the dataset but the Explained Ratio graph between number of components and Variance shows straight line which dipicts no strong correlation between the features.\n",
    "\n",
    "-Here we concluded that tha data has already selected features so we used dataset as it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9fb07",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95d4c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['target','ID_code'],axis=1)\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b462d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>-0.6209</td>\n",
       "      <td>5.6669</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>-3.6797</td>\n",
       "      <td>6.0019</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>6.1629</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>-2.1926</td>\n",
       "      <td>8.7542</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>-0.4541</td>\n",
       "      <td>9.3688</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
       "0        8.9255 -6.7863  11.9081  5.0930  11.4607  -9.2834  5.1187  18.6266   \n",
       "1       11.5006 -4.1473  13.8588  5.3890  12.3622   7.0433  5.6208  16.5338   \n",
       "2        8.6093 -2.7457  12.0805  7.8928  10.5825  -9.0837  6.9427  14.6155   \n",
       "3       11.0604 -2.1518   8.9522  7.1957  12.5846  -1.8361  5.8428  14.9250   \n",
       "4        9.8369 -1.4834  12.8746  6.6375  12.2772   2.4486  5.9405  19.2514   \n",
       "...         ...     ...      ...     ...      ...      ...     ...      ...   \n",
       "199995  11.4880 -0.4956   8.2622  3.5142  10.3404  11.6081  5.6709  15.1516   \n",
       "199996   4.9149 -2.4484  16.7052  6.6345   8.3096 -10.5628  5.8802  21.5940   \n",
       "199997  11.2232 -5.0518  10.5127  5.6456   9.3410  -5.4086  4.5555  21.5571   \n",
       "199998   9.7148 -8.6098  13.6104  5.7930  12.5173   0.5339  6.0479  17.0152   \n",
       "199999  10.8762 -5.7105  12.1183  8.0328  11.5577   0.3488  5.2839  15.2058   \n",
       "\n",
       "         var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "0      -4.9200  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227   \n",
       "1       3.1468  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   \n",
       "2      -4.9193  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   \n",
       "3      -5.8609  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347   \n",
       "4       6.2654  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
       "...        ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "199995 -0.6209  5.6669  ...   6.1415  13.2305   3.9901   0.9388  18.0249   \n",
       "199996 -3.6797  6.0019  ...   4.9611   4.6549   0.6998   1.8341  22.2717   \n",
       "199997  0.1202  6.1629  ...   4.0651   5.4414   3.1032   4.8793  23.5311   \n",
       "199998 -2.1926  8.7542  ...   2.6840   8.6587   2.7337  11.1178  20.4158   \n",
       "199999 -0.4541  9.3688  ...   8.9842   1.6893   0.1276   0.3766  15.2101   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "0       -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "1        2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "2        3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "3       -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4       -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "199995  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "199996   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "199997  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "199998  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "199999  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[200000 rows x 200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4d4973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "199995    0\n",
       "199996    0\n",
       "199997    0\n",
       "199998    0\n",
       "199999    0\n",
       "Name: target, Length: 200000, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3517adc9",
   "metadata": {},
   "source": [
    "# Balancing the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04b11bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 179902, 1: 20098})\n",
      "Counter({0: 179902, 1: 179902})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "# importing counter to check count of each label\n",
    "from imblearn.over_sampling import SMOTE \n",
    "#for balancing the data\n",
    "sm=SMOTE()#object creation\n",
    "print(Counter(y))\n",
    "# checking count for each class \n",
    "X_sm,y_sm=sm.fit_resample(X,y)\n",
    "#applying sampling on target variable \n",
    "print(Counter(y_sm))\n",
    "# checking count after sampling for  each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb97644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preparing training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f19ec9",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77af5ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#importing decision tree from sklearn.tree\n",
    "dt=DecisionTreeClassifier()\n",
    "#object creation for decision tree  \n",
    "dt.fit(X_train,y_train)\n",
    "#training the model\n",
    "y_hat=dt.predict(X_test)#prediction\n",
    "y_hat#predicted values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fc18b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predict=dt.predict(X_train)#predicting training data to check training performance \n",
    "y_train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4cbab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evalauting the model\n",
    "from sklearn.metrics import accuracy_score,classification_report,f1_score#importing mertics to check model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5c1a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    134868\n",
      "           1       1.00      1.00      1.00    134985\n",
      "\n",
      "    accuracy                           1.00    269853\n",
      "   macro avg       1.00      1.00      1.00    269853\n",
      "weighted avg       1.00      1.00      1.00    269853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_train_predict))# it will give precision,recall,f1 scores and accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2b4776c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7702971617880846"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test acc\n",
    "test_acc=accuracy_score(y_test,y_hat)#testing accuracy \n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00a59932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7799245893956501"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test score\n",
    "test_f1=f1_score(y_test,y_hat)#f1 score\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f091a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76     45034\n",
      "           1       0.75      0.82      0.78     44917\n",
      "\n",
      "    accuracy                           0.77     89951\n",
      "   macro avg       0.77      0.77      0.77     89951\n",
      "weighted avg       0.77      0.77      0.77     89951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_hat))# for  testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5519730",
   "metadata": {},
   "source": [
    "# Hyperparameters of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef2526b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf429b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4332 candidates, totalling 12996 fits\n"
     ]
    }
   ],
   "source": [
    "#creating dictionary--> key value pair of hyperparameters having key as parameter and values as its values\n",
    "params = {\n",
    "    \"criterion\":(\"gini\", \"entropy\"), #quality of split\n",
    "    \"splitter\":(\"best\", \"random\"), # searches the features for a split\n",
    "    \"max_depth\":(list(range(1, 20))), #depth of tree range from 1 to 19\n",
    "    \"min_samples_split\":[2, 3, 4],    #the minimum number of samples required to split internal node\n",
    "    \"min_samples_leaf\":list(range(1, 20)),#minimum number of samples required to be at a leaf node,we are passing list which is range from 1 to 19 \n",
    "}\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=3)#object creation for decision tree with random state 3\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"f1\", n_jobs=-1, \n",
    "                       verbose=3, cv=3)\n",
    "tree_cv.fit(X_train,y_train)#training data on gridsearch cv\n",
    "best_params = tree_cv.best_params_#it will give you best parameters \n",
    "print(f\"Best paramters: {best_params})\")#printing  best parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting 3 folds for each of 4332 candidates, totalling 12996 fits\n",
    "Bestparamters: ({'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv.best_params_#getting best parameters from cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22cc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv.best_score_#getting best score form cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test=accuracy_score(y_test,y_hat1)#checking accuracy\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f1=f1_score(y_test,y_hat1)#f1_score\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_hat1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48663df8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a698c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)  \n",
    "rf_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fecbb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19e12d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07c98628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     45034\n",
      "           1       0.98      0.95      0.96     44917\n",
      "\n",
      "    accuracy                           0.97     89951\n",
      "   macro avg       0.97      0.97      0.97     89951\n",
      "weighted avg       0.97      0.97      0.97     89951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,f1_score\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c2c0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647812166488794"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_Score=f1_score(y_test,y_predict)\n",
    "f_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b5bf8",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18857cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]#List Comprehension-using for loop in list\n",
    "max_features = ['auto', 'sqrt']#maximum number of features allowed to try in individual tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]#List Comprehension-using for loop in list\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]#minimum number of samples required to split an internal node\n",
    "min_samples_leaf = [1, 2, 4]#minimum number of samples required to be at a leaf node.\n",
    "bootstrap = [True, False]#sampling \n",
    "\n",
    "#dictionary for hyperparameters\n",
    "random_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "rf_clf1 = RandomForestClassifier(random_state=42)#model\n",
    "\n",
    "rf_cv = RandomizedSearchCV(estimator=rf_clf1, scoring='f1',param_distributions=random_grid, n_iter=100, cv=3, \n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_cv.fit(X_train, y_train)##training data on randomsearch cv\n",
    "rf_best_params = rf_cv.best_params_##it will give you best parameters \n",
    "print(f\"Best paramters: {rf_best_params})\")##printing  best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf2 = RandomForestClassifier(n_estimators=400, min_samples_split= 2, min_samples_leaf= 1, max_features= 'sqrt', max_depth= None, bootstrap= False)#passing best parameter to randomforest\n",
    "rf_clf2.fit(X_train, y_train)#training \n",
    "y_predict=rf_clf2.predict(X_test)#testing\n",
    "f1_score=f1_score(y_test,y_pred\n",
    "                  ict)+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "+-+++#checking performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f573fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19882bd0",
   "metadata": {},
   "source": [
    "# Gradient Boosting DecisionTree (GBDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68c4872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing the model library\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm=GradientBoostingClassifier() ## object creation\n",
    "gbm.fit(X_train,y_train) ## fitting the data\n",
    "y_gbm=gbm.predict(X_test)#predicting the price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c97dbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8218269252176236"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## evaluatin the model\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,classification_report# to check model performance\n",
    "recall_scor=recall_score(y_test,y_gbm)\n",
    "recall_scor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2325a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90     45034\n",
      "           1       0.90      0.89      0.89     44917\n",
      "\n",
      "    accuracy                           0.89     89951\n",
      "   macro avg       0.89      0.89      0.89     89951\n",
      "weighted avg       0.89      0.89      0.89     89951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e032734",
   "metadata": {},
   "source": [
    "# GB_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dd407e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16e4a575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 201 entries, target to var_199\n",
      "dtypes: float64(200), int64(1)\n",
      "memory usage: 306.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6049f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model creation\n",
    "from xgboost import XGBClassifier#importing the model library\n",
    "xgb_r=XGBClassifier() ## object creation\n",
    "xgb_r.fit(X_train,y_train)# fitting the data\n",
    "y_hat=xgb_r.predict(X_test)#predicting the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22c3eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90     45034\n",
      "           1       0.90      0.89      0.89     44917\n",
      "\n",
      "    accuracy                           0.89     89951\n",
      "   macro avg       0.89      0.89      0.89     89951\n",
      "weighted avg       0.89      0.89      0.89     89951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49a9c152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8872364583565242"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score1=recall_score(y_test,y_hat)\n",
    "recall_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed675b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}\n",
    "\n",
    "XGB=XGBClassifier(random_state=42,verbosity=0,silent=0)\n",
    "rcv= RandomizedSearchCV(estimator=XGB, scoring='f1',param_distributions=param_grid, n_iter=100, cv=3, \n",
    "                               verbose=2, random_state=42, n_jobs=-1)\n",
    "rcv.fit(X_train, y_train)##training data on randomsearch cv\n",
    "cv_best_params = rcv.best_params_##it will give you best parameters \n",
    "print(f\"Best paramters: {cv_best_params})\")##printing  best parameters\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB2=XGBClassifier(reg_lambda= 12.8, reg_alpha= 0.1, n_estimators=150, max_depth=5, learning_rate=0.1, gamma=0.8)\n",
    "XGB2.fit(X_train, y_train)#training \n",
    "y_predict=XGB2.predict(X_test)#testing\n",
    "f1_score=f1_score(y_predict,y_test)#checking performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ec0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score#calling variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79b7b3",
   "metadata": {},
   "source": [
    "# Conclution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf34b9",
   "metadata": {},
   "source": [
    "- We tried 4 difference models as our first step in modelling process, to evaluate & choose the best model as our baseline       model.\n",
    "\n",
    "- Our model focused on F1 Score.\n",
    "\n",
    "- The datset was a imbalance dataset. so we balanced the dataset\n",
    "\n",
    "- Based on the result, we found out that RandomForest Classifer with highest F1 Score 0.90 or 90%\n",
    "\n",
    "- We are able to minimize False Negative and False positive rate by maximizing our evaluation metric which is F1 Score by 90%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
